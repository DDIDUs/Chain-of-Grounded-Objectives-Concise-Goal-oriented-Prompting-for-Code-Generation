max_tokens: 16396
model: meta-llama/Llama-3.1-70B-Instruct
platform: vllm
temperature: 0
top_p: 1